{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXe31uMdeegs",
        "colab_type": "code",
        "outputId": "8b9fb8d1-7275-4d79-c3da-cd432ba010d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUa__kBme1gL",
        "colab_type": "code",
        "outputId": "9d61e55f-a910-4b7a-c171-9910f6a09082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# download the train dataset\n",
        "# Note that the url needs to be updated with current key ids which would be valid be limited duration of time\n",
        "# url can be obtained by right-click and copy link location of test dataset in the download section of xview2.org downloads  \n",
        "\n",
        "import urllib.request\n",
        "testfile = urllib.request\n",
        "# format : testfile.urlretrieve('...URL...','train.tar.gz')\n",
        "testfile.urlretrieve('https://download.xview2.org/train.tar.gz?Expires=1585237989&Signature=gcWMAkD4a-bnIfrQ~bRqRMDRSm7mQuoQLJCIvHY2EI4oBUdM2hgmWEr8e04e8i1PlN3Y6KglbIpJRXhxfc5Jo9PUSXlP~t~gMPyvGp5~2Yppop8h6l2KWI5QY0JbmFD~J9nLMY4uP6JmLwVYuEQP63WD9VpiRIr8RwbyJtpuai8WQGLVdNcXnF6O-gUuund69TBKHNazjVrHUUf4AKWQfG5vMBZjicoEljhlSY7wlR9HADifiW10bhiv8SW7kynl7eUzhhlxk8EfNKvrV5vhHdwRiJGVuF2Phva-U5rz9geqSvOj6TQEhDWuLrDuTrTm2VFD7m8scYEEyjQvaAvKnw__&Key-Pair-Id=APKAIKGDJB5C3XUL2DXQ','train.tar.gz')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('train.tar.gz', <http.client.HTTPMessage at 0x7fad97fbd6a0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46ZGOTTVfrwz",
        "colab_type": "code",
        "outputId": "206e510f-f789-4dc0-8081-83e8c37fedae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "!git clone https://'enter ur git id':'enter ur password'@github.com/ham952/xbd_training.git \n",
        "#e-g !git clone https://ham952:tHisIsn8pswrd@github.com/ham952/xbd_training.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'xbd_training'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 57 (delta 16), reused 37 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (57/57), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H08nqPxPiedA",
        "colab_type": "code",
        "outputId": "21987267-d501-4557-ab92-526af2e3492e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/xbd_training"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/xbd_training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLYzVbz_iusY",
        "colab_type": "code",
        "outputId": "434475cb-a0c2-4d20-c969-4d26dfac0be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mcallbacks\u001b[0m/  \u001b[01;34moutput\u001b[0m/          README.md         setup.txt\n",
            "\u001b[01;34mcsv\u001b[0m/        process_data.py  requirements.txt  xview2_training_v5.py\n",
            "\u001b[01;34mmodel\u001b[0m/      \u001b[01;34mprocessed_data\u001b[0m/  setup_gpu.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vZaoiaDn4LR",
        "colab_type": "code",
        "outputId": "908b02b3-120c-4e2c-9775-abef8e2379c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Creating \"Dataset\" folder\n",
        "import os\n",
        "dirName = 'Dataset'\n",
        " \n",
        "try:\n",
        "    # Create target Directory\n",
        "    os.mkdir(dirName)\n",
        "    print(\"Directory \" , dirName ,  \" Created \") \n",
        "except FileExistsError:\n",
        "    print(\"Directory \" , dirName ,  \" already exists\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory  Dataset  Created \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMrm92N8UWtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#move zip file in Dataset Directory\n",
        "!mv \"/content/train.tar.gz\" \"./Dataset/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqXR280Hixoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip operation\n",
        "!tar -xvzf ./Dataset/train.tar.gz -C ./Dataset/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY9cO7ZEjLe8",
        "colab_type": "code",
        "outputId": "b47a12f9-b7a7-4468-bbc6-4bfc32eccf2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "os.remove('./Dataset/train.tar.gz')\n",
        "print('redundant zip file removed')\n",
        "files = os.listdir('./Dataset/train/images/') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tar file removed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1y0PszAkggq",
        "colab_type": "code",
        "outputId": "83ea3bf9-81c7-4c81-ab06-c3a254d3a36b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print ('total number of HQ images : ',len(files)) # 5598"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total number of HQ images 5598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL3gxYbXkjaV",
        "colab_type": "code",
        "outputId": "70e2b1ee-c3e7-4a35-c2c8-5408f3f62952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "# processing the HQ images to obtain training dataset\n",
        "!python process_data.py --input_dir ./Dataset --output_dir ./processed_data --output_dir_csv ./csv --val_split_pct 0.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Started Processing for Data\n",
            " 64% 3593/5598 [04:12<02:39, 12.58it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQkB4EMgk_Tn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_files = os.listdir('./processed_data/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MK_lSXfm5DG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('total number of processed images : ',len(processed_files)) #162788"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu3ynOP-Mzjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Running the main code\n",
        "!python xview2_training_v5.py --train_data ./processed_data --train_csv ./csv --test_data ./processed_data --test_csv ./csv --model_out ./output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md1OA5p7m8w-",
        "colab_type": "code",
        "outputId": "41214ad4-701a-41bd-8a53-af86f077e575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Example of code run with 0.1:0.9 (valid_images:train images), initial learning rate 0.1 , optimizer stuck at a local minima\n",
        "!python xview2_training_v5.py --train_data ./processed_data --train_csv ./csv --test_data ./processed_data --test_csv ./csv --model_out '/content/drive/My Drive/xbdResults/log01'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "INFO:root:Started Model Training\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1335: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-03-25 14:13:43.036155: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-03-25 14:13:43.036364: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3048a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-25 14:13:43.036396: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-03-25 14:13:43.038319: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-25 14:13:43.145471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-25 14:13:43.146127: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3048bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-25 14:13:43.146155: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-03-25 14:13:43.146356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-25 14:13:43.146855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-25 14:13:43.147174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-25 14:13:43.148734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-25 14:13:43.150284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-03-25 14:13:43.150632: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-03-25 14:13:43.152216: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-03-25 14:13:43.152947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-03-25 14:13:43.156124: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-25 14:13:43.156259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-25 14:13:43.156919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-25 14:13:43.157459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-03-25 14:13:43.157529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-25 14:13:43.158717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-25 14:13:43.158743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-03-25 14:13:43.158754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-03-25 14:13:43.158966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-25 14:13:43.159627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-25 14:13:43.160198: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-03-25 14:13:43.160238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "[INFO] total training images : 146508\n",
            "[INFO] total test images : 16279\n",
            "[INFO] printing class weights : {0: 0.3378064301920204, 1: 2.7311162478562374, 2: 2.874735107134448, 3: 3.0701592623637888}\n",
            "[INFO] performing training data augmentation\n",
            "Found 146508 validated image filenames belonging to 4 classes.\n",
            "Found 16279 validated image filenames belonging to 4 classes.\n",
            "Learning rate:  0.1\n",
            "[INFO] compiling model with cusutom loss function...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "[INFO] training network...\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/100\n",
            "Learning rate:  0.1\n",
            "2020-03-25 14:14:11.587491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-25 14:14:11.870439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2290/2290 [==============================] - 556s 243ms/step - loss: 20.1511 - acc: 0.7397 - f1: 0.7397 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 2/100\n",
            "Learning rate:  0.1\n",
            "2290/2290 [==============================] - 543s 237ms/step - loss: 20.1461 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 3/100\n",
            "Learning rate:  0.1\n",
            "2290/2290 [==============================] - 542s 237ms/step - loss: 20.1519 - acc: 0.7400 - f1: 0.7400 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 4/100\n",
            "Learning rate:  0.1\n",
            "2290/2290 [==============================] - 536s 234ms/step - loss: 20.1440 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 5/100\n",
            "Learning rate:  0.1\n",
            "2290/2290 [==============================] - 539s 235ms/step - loss: 20.1450 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 6/100\n",
            "Learning rate:  0.1\n",
            "2290/2290 [==============================] - 539s 235ms/step - loss: 20.1422 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.031622777072899885.\n",
            "Epoch 7/100\n",
            "Learning rate:  0.1\n",
            "2290/2290 [==============================] - 538s 235ms/step - loss: 20.1434 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 8/100\n",
            "Learning rate:  0.1\n",
            "2290/2290 [==============================] - 538s 235ms/step - loss: 20.1458 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 9/100\n",
            "Learning rate:  0.1\n",
            "2290/2290 [==============================] - 541s 236ms/step - loss: 20.1440 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 10/100\n",
            "Learning rate:  0.1\n",
            "2290/2290 [==============================] - 552s 241ms/step - loss: 20.1463 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 11/100\n",
            "Learning rate:  0.1\n",
            "2290/2290 [==============================] - 554s 242ms/step - loss: 20.1486 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 12/100\n",
            "Learning rate:  0.01\n",
            "2290/2290 [==============================] - 546s 238ms/step - loss: 20.1486 - acc: 0.7400 - f1: 0.7400 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0031622775894859655.\n",
            "Epoch 13/100\n",
            "Learning rate:  0.01\n",
            "2290/2290 [==============================] - 539s 235ms/step - loss: 20.1457 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 14/100\n",
            "Learning rate:  0.01\n",
            "2290/2290 [==============================] - 540s 236ms/step - loss: 20.1498 - acc: 0.7400 - f1: 0.7400 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 15/100\n",
            "Learning rate:  0.01\n",
            "2290/2290 [==============================] - 540s 236ms/step - loss: 20.1550 - acc: 0.7400 - f1: 0.7400 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 16/100\n",
            "Learning rate:  0.01\n",
            "2290/2290 [==============================] - 539s 235ms/step - loss: 20.1439 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 17/100\n",
            "Learning rate:  0.01\n",
            "2290/2290 [==============================] - 537s 235ms/step - loss: 20.1537 - acc: 0.7400 - f1: 0.7400 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 18/100\n",
            "Learning rate:  0.01\n",
            "2290/2290 [==============================] - 535s 234ms/step - loss: 20.1469 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0031622775894859655.\n",
            "Epoch 19/100\n",
            "Learning rate:  0.01\n",
            "2290/2290 [==============================] - 539s 236ms/step - loss: 20.1509 - acc: 0.7400 - f1: 0.7400 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 20/100\n",
            "Learning rate:  0.01\n",
            "2290/2290 [==============================] - 533s 233ms/step - loss: 20.1445 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 21/100\n",
            "Learning rate:  0.01\n",
            "2290/2290 [==============================] - 543s 237ms/step - loss: 20.1527 - acc: 0.7400 - f1: 0.7400 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 22/100\n",
            "Learning rate:  0.001\n",
            "2290/2290 [==============================] - 545s 238ms/step - loss: 20.1439 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 23/100\n",
            "Learning rate:  0.001\n",
            "2290/2290 [==============================] - 542s 237ms/step - loss: 20.1504 - acc: 0.7400 - f1: 0.7400 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 24/100\n",
            "Learning rate:  0.001\n",
            "2290/2290 [==============================] - 542s 237ms/step - loss: 20.1451 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00031622778103685084.\n",
            "Epoch 25/100\n",
            "Learning rate:  0.001\n",
            "2290/2290 [==============================] - 543s 237ms/step - loss: 20.1480 - acc: 0.7400 - f1: 0.7400 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 26/100\n",
            "Learning rate:  0.001\n",
            "2290/2290 [==============================] - 545s 238ms/step - loss: 20.1537 - acc: 0.7400 - f1: 0.7400 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 27/100\n",
            "Learning rate:  0.001\n",
            "2290/2290 [==============================] - 543s 237ms/step - loss: 20.1445 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 28/100\n",
            "Learning rate:  0.001\n",
            "2290/2290 [==============================] - 549s 240ms/step - loss: 20.1451 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 29/100\n",
            "Learning rate:  0.001\n",
            "2290/2290 [==============================] - 545s 238ms/step - loss: 20.1469 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 30/100\n",
            "Learning rate:  0.001\n",
            "2290/2290 [==============================] - 547s 239ms/step - loss: 20.1498 - acc: 0.7400 - f1: 0.7400 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00031622778103685084.\n",
            "Epoch 31/100\n",
            "Learning rate:  0.001\n",
            "2290/2290 [==============================] - 543s 237ms/step - loss: 20.1502 - acc: 0.7400 - f1: 0.7400 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 32/100\n",
            "Learning rate:  0.001\n",
            "2290/2290 [==============================] - 547s 239ms/step - loss: 20.1452 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 33/100\n",
            "Learning rate:  0.001\n",
            "2290/2290 [==============================] - 545s 238ms/step - loss: 20.1450 - acc: 0.7401 - f1: 0.7401 - val_loss: 6.9830 - val_acc: 0.7367 - val_f1: 0.7367\n",
            "Epoch 34/100\n",
            "Learning rate:  0.001\n",
            "1724/2290 [=====================>........] - ETA: 2:10 - loss: 20.1223 - acc: 0.7401 - f1: 0.7401Traceback (most recent call last):\n",
            "  File \"xview2_training_v5.py\", line 314, in <module>\n",
            "    main()\n",
            "  File \"xview2_training_v5.py\", line 310, in main\n",
            "    train_model(args.train_data,train_csv_path,args.test_data,test_csv_path,args.model_in,callbacks)   \n",
            "  File \"xview2_training_v5.py\", line 242, in train_model\n",
            "    callbacks=callbacks\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1658, in fit_generator\n",
            "    initial_epoch=initial_epoch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\", line 181, in fit_generator\n",
            "    generator_output = next(output_generator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 603, in get\n",
            "    inputs = future.get(timeout=30)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 638, in get\n",
            "    self.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 635, in wait\n",
            "    self._event.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 551, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 299, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AvhT8haJm31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}